<!--
Configuration
-->
    <chapter id="Configuration">
        <title>Configuration</title>
        <chapterinfo>
       </chapterinfo>
    <para>
    As it was mentioned above <application>PoD</application> consists of several modules
    and to fine tune <application>PoD</application> one may want to configure some of these modules.
    Recommended only for advanced users.
    </para>
    <sect1 id="PoD_CFG">
      <title>PoD user defaults configuration</title>
      <para>
	Since PoD v2.1.1 a user defaults configuration file is support. This is a general configuration of PoD.
	All modules read from that file. By default it is located in <filename  class="directory">$POD_LOCATION/etc/</filename>
and is called <filename>PoD.cfg</filename>.
      </para>
      <para>
       The <filename>PoD.cfg</filename> is a simple INI-like configuration file. Configuration file syntax is line based:
        <itemizedlist>
        <listitem><para>A line in the form:
<screen>
key_name=value
</screen>
gives a value to an option.
         </para></listitem>
         <listitem><para>A line in the form:
<screen>
[section name]
</screen>    
        introduces a new section in the configuration file.
        </para></listitem>
        <listitem><para>The # character introduces a comment that spans until the end of the line.</para>
        <para>The option names are relative to the section names, so the following configuration file part:
<screen>
[gui.accessibility]
visual_bell=yes
</screen>
        is equivalent to
<screen>
gui.accessibility.visual_bell=yes
</screen>      
       </para></listitem>
       </itemizedlist>
      </para>
	<para>
	PoD is shipped with default values in PoD.cfg and should work out of the box.  
	</para>

    <para>
    <table id="POD_SERVER_CFG_TABLE">
		<title>PoD server configuration</title>
  		<tgroup cols="2">
    		<thead>
      	<row>
        		<entry>key</entry>
            <entry>value</entry>
        		<entry>Description</entry>        
      	</row>
    		</thead>
    		<tbody>
        </tbody>
   	</tgroup>
		</table>
    </para>

    <para>
    <table id="POD_WORKER_CFG_TABLE">
		<title>PoD worker configuration</title>
  		<tgroup cols="2">
    		<thead>
      	<row>
        		<entry>key</entry>
            <entry>value</entry>
        		<entry>Description</entry>        
      	</row>
    		</thead>
    		<tbody>
        </tbody>
   	</tgroup>
		</table>
    </para>

    <para>
    <table id="LSF_CFG_TABLE">
		<title>LSF plug-in configuration</title>
  		<tgroup cols="2">
    		<thead>
      	<row>
        		<entry>key</entry>
            <entry>value</entry>
        		<entry>Description</entry>        
      	</row>
    		</thead>
    		<tbody>
      		<row>
        			<entry>lsf_plugin.email_job_output</entry>
              <entry>yes/no (default: no)</entry>
        			<entry>The parameter specifies whether job's output is sent to the user by mail.
              if "no" is set, output will be delivered the log directory in std_[INDEX].err and std_[INDEX].out files</entry>
      		</row>
      		<row>
        			<entry>lsf_plugin.upload_job_log</entry>
              <entry>yes/no (default: no)</entry>
        			<entry>The parameter specifies whether to upload jobs log files from workers when PoD jobs are completed. 
              Jobs log files include a full log of PROOF, XROOTD and pod-agent's log files.</entry>        
      		</row>
        </tbody>
   	</tgroup>
		</table>
    </para>

  <para>
    <table id="PBS_CFG_TABLE">
		<title>PBS plug-in configuration</title>
  		<tgroup cols="2">
    		<thead>
      	<row>
        		<entry>key</entry>
            <entry>value</entry>
        		<entry>Description</entry>        
      	</row>
    		</thead>
    		<tbody>
      		<row>
        			<entry>pbs_plugin.shared_home</entry>
              <entry>yes/no (default: no)</entry>
        			<entry>The parameter specifies whether a shared home files system is used. 
              If "no" is set, than PoD will use the scp command to stagin/out required files.</entry>
      		</row>
      		<row>
        			<entry>pbs_plugin.upload_job_log</entry>
              <entry>yes/no (default: no)</entry>
        			<entry>The parameter specifies whether to upload jobs log files from workers when PoD jobs are completed. 
              Jobs log files include a full log of PROOF, XROOTD and pod-agent's log files.</entry>        
      		</row>
        </tbody>
   	</tgroup>
		</table>
    </para>

    </sect1>

    <sect1 id="GAW">
      <title>GAW</title>
      <para>
      GAW needed for gLite plug-in (if you want to use gLite workers as your PROOF workers).
      There is GAW's configuration file in the
      <filename class="directory">/tmp/test/PoDpackage/etc</filename> directory, it's called
      <filename>glite-api-wrapper.cfg.xml</filename>. Through this file one can configure GAW engine.
      The file is an XML file and it's XML Schema documentation and description of all configuration keys could
      be found by the following <ulink url="http://www-linux.gsi.de/~manafov/D-Grid/docz/">link</ulink>.
      </para>
      <para>
      Since gLite plug-in uses GAW to submit gLite jobs the important parameter to configure would be
      a <varname>wmp_endpoint</varname>. This parameter holds the value for the default WMProxy endpoint to use.
      <tip>
      <para>
      GAW has a smart method for endpoint guessing. So, if you have could configured gLite UI,
      in terms that WMProxy endpoints are configured for your VO, then GAW will find the best match and
      will use it, and you therefore could just keep the <varname>wmp_endpoint</varname> value empty or
      you could remove this key from the configuration file at all. Otherwise GAW will use the value from
      the configuration file.      
      </para>
      </tip>
        All other settings may be changed to adjust PoD according to personal needs.
        </para>
    </sect1>
    <sect1 id="XROOTD">
      <title>XROOTD</title>
      <para>
      There is a default XROOTD configuration file, which is located in the <filename class="directory">/tmp/test/PoDpackage/etc</filename>
      directory and it's called <filename>xpd.cf</filename>. PoD uses this file to configure both local redirector and
      remote workers.
            
      <tip>
      <para>
      In <ulink url="http://xrootd.slac.stanford.edu/">XROOTD documentation</ulink>
      you can find details of fine tuning of xrootd. But it is only recommended for advanced users.
      </para>
      </tip>
      
      The default xrootd configuration, which comes with PoD should be sufficient for basic operations.
      In most of use cases it is not needed to modify the configuration.
      </para>
      <para>
      PoD is only meant to help to setup a PROOF cluster on the fly using a remote worker nodes. A data access is not
      really a part of responsibility of PoD. The default configuration of PoD offers a possibility to access data
      files from the server machine (user's workspace) using xrootd vie port 20094 and the following shared folder
      <filename class="directory">/tmp/</filename>. Users may want to use another xrootd facility to access data or
      reconfigure PoD's xrootd to use different port and location. To do so the following variables must be updated in
      <filename>xpd.cf</filename> file: <varname>xrd.port</varname>, <varname>xrootd.export</varname> (for the server host),
      <varname>olb.path</varname>(for the server host).

      <tip>
      <para>
      It is recommended to use your own xrootd facility to access data files.
      Using user's local machine for data access is very
      inefficient. PoD provides this ability only for testing purpose.
      </para>
      </tip>
      
      <tip>
      <para>
      By a slight change of default PoD's <filename>xrd.cf</filename>, users can have a dynamic xrootd pools on remote WNs.
      To do so, you need to set <varname>all.role</varname> parameter to <constant>manager</constant> instead of
      <constant>server</constant> (default) for your UI host.
		<para>
		
		But, PoD doesn't provide yet [<ulink url="https://subversion.gsi.de/trac/dgrid/ticket/53">PoD Trac Ticket #53</ulink>]
		a proxy mechanism for xrootd file transfer,
		WNs therefore must have XROOTD ports opened in both directions (which is very unusual for Grid worker nodes).
		Once again, for best performance and security reasons it is recommend to use external data storage,
		like external xrootd cluster or any other data storage supported by ROOT.
		</para> 
      </para>
      </tip>
      
      </para>      
    </sect1>
    <sect1 id="A_JDL_file">
      <title>A JDL file</title>
      <para>
      PoD submits its workers with help of a JDL file. Default JDL files are a part of PoD packages.
      User can find them in the <filename class="directory">/tmp/test/PoDpackage/etc</filename> folder.
      There are <filename>gLitePROOF.jdl</filename> and <filename>gLitePROOF_FZK.jdl</filename> files in this folder.
      The first file is the generic PoD jdl file and the second one is optimized for a specific FZK gLite computing element.
        This files could be used as examples or real job files.
      </para>
      <para>
      It is allowed to modify JDL files or create a custom one in order to tune job requirements for
      a specific site or a resource.
      The file in anyway must be inherited from <filename>gLitePROOF.jdl</filename>.       
      </para>
      <important><para>
       If you want to use a custom JDL file, be advised that
       the following keys of JDL file must be kept unchanged:
       RetryCount, ParameterStart, PARAMETERS, JobType, Executable, ParameterStep, StdOutput, OutputSandbox, Type,
       StdError, InputSandbox. Otherwise PoD functionality could be broken.
      </para></important>
      
    </sect1>    
  </chapter>
